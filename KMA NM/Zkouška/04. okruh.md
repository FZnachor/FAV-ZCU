**Stacionární iterační metody pro soustavy lineárních algebraických rovnic. Jacobiho a Gaussova-Seidelova metoda, SOR metoda. Nutná a postačující podmínka konvergence iterační metody, postačující podmínka konvergence iterační metody.**

### Iterační metody

- používány pro řídké matice

Obecný zápis
- $Ax - b = 0 \leftrightarrow F(x) = 0$ přepíšeme na tvar $x = Hx+g \leftrightarrow x = \Phi(x)$
- iterační formule ... $x^{(k+1)} = H \cdot x^{(k)} + g$
	- $H$ rozhoduje o kvalitě metody
- počáteční aproximace $x^{(0)}$, zastavovací podmínka $\Vert x^{(k)}-c^{(k-1)}\Vert < \epsilon$

**Jacobiho metoda**
- z $i$-té rovnice vyjádřím $i$-tou složku vektoru $x$
	- $i$-tá rovnice ... $a_{i1}x_{1} + a_{i2}x_{2} + \dots a_{in}x_{n} = b_{i}$
- iterační formule
	- $\displaystyle x_{i}^{(k+1)} = \frac{1}{a_{ii}}\left( b_{i} - \sum^n_{j=1; j\neq i} a_{ij}x_{j}^{(k)} \right)$ pro $a_{ii} \neq 0$
	- $H$ ... řádky jsou jednotlivá vyjádření $x_{i}$
	- $g$ ... sestavený z členů bez $x$ ve vyjádření $x_{i}$

**Gaussova-Seidelova metoda**
- stejný princip jako u Jacobihovy metody, ale pokud při výpočtu $(k+1)$-iterace již známe $(k+1)$ iteraci u některých složek, tak ji použijeme
- iterační formule
	- $\displaystyle x_{i}^{(k+1)} = \frac{1}{a_{ii}}\left( b_{i} - \sum^{i-1}_{j=1} a_{ij}x_{j}^{(k+1)} - \sum^{n}_{j=i+1} a_{ij} x_{j}^{(k) }\right)$

**SOR metoda**
- princip
	- vychází z Gauss-Seidelovy metody
	- vyjádříme $(k+1)$-iteraci pomocí $k$-té iterace a změny ... $x_{i}^{(k+1)} = x_{i}^{(k)} + r_{i}^{(k)}$
	- idea: k urychlení nepřičteme změnu $r_{i}^{(k)}$ ale její násobek $\omega\cdot r_{i}^{(k)}$
- iterační formule
	- $\displaystyle x_{i}^{(k+1)} = \omega\cdot x_{i,GS}^{(k+1)} + (1-\omega)x_{i}^{(k)}$
	- lineární kombinace $(k+1)$-iterace GS-metody a $k$-té iterace metody SOR
- volba $\omega$
	- musíme si zvolit parametr $\omega$
	- tento parametr může metodu zhoršit či vylepšit oproti GS
	- vzorec, který (ne vždy) dokáže vypočítat optimální $\omega$
		- $\displaystyle\omega_\text{opt} = \frac{2}{1 + \sqrt{ 1- \rho(H_{J}) }}$
		- $\rho(H_{J})$ ... spektrální poloměr Jacobiho matice $H$

### Konvergence iteračních metod

$\displaystyle\lim_{ x \to \infty } x^{(k)} = x^*$

Nutná a postačující podmínka konvergence
- $\rho(H) = \max|\lambda_{i}(H)| < 1 \Longleftrightarrow$ metoda konverguje $\Longleftrightarrow$ úloha je stabilní
	- $\rho(H)$ ... spektrální poloměr matice $H$ = maximální vl. číslo matice $H$ v abs. hodnotě
- čím blíž bude spektrální poloměr 1, tím bude metoda pomalejší
	- snaha, dostat ho co nejvíce k 0

Postačující podmínka konvergence
- $\Vert H\Vert \leq q < 1 \implies$ metoda je konvergentní
	- multiplikativní maticová norma: $\Vert A\cdot B\Vert \leq \Vert A\Vert\cdot\Vert B\Vert$
- podmínka pro konvergenci SOR
	- $\rho(H_{SOR}) \geq |\omega-1| \quad \forall \omega \in R$

Konvergenční věty
- podmínky pro $H$ jsou nepraktické, $H$ je těžko spočitatelná
- $A$ je ostře diagonálně dominantní $\implies$ konverguje Jacobiho i GS metoda pro libovolnou volbu $x_{0}$
- $A$ je symetrická a poz. definitní $\implies$ konverguje GS metoda
- SOR metoda konverguje $\implies 0 < \omega < 2$
- $A$ je symetrická a poz. definitní, $0 < \omega < 2 \implies$ SOR metoda konverguje
